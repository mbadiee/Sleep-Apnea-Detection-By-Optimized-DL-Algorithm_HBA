{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBA_bfRBMFAh",
        "outputId": "1c053dee-f374-411b-b560-07a7f86f731b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "Ga3vpjeeInMF",
        "outputId": "bd9ece0e-81eb-4b0d-d975-b5f2fd997dfd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c12651c3-2879-4b16-8111-4bb1438ef35e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c12651c3-2879-4b16-8111-4bb1438ef35e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrX9UhgNIjk8"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvghRGZxGKnn",
        "outputId": "5abcb885-874b-481c-ff0d-021256f5b031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading apnea-ecg-database.zip to /content\n",
            "100% 315M/315M [00:04<00:00, 86.0MB/s]\n",
            "100% 315M/315M [00:04<00:00, 73.5MB/s]\n",
            "Source code downloaded to /content/rri-amplitudes.ipynb\n"
          ]
        }
      ],
      "source": [
        "#https://www.kaggle.com/code/bettycxh06/rri-amplitudes/input\n",
        "!kaggle datasets download -d bettycxh06/apnea-ecg-database\n",
        "\n",
        "!kaggle kernels pull bettycxh06/rri-amplitudes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpdaFcLeMklA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceqvdCwFMt5T",
        "outputId": "8dc8744f-3f0a-4041-a087-3808086de26e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'apnea-ecg-database.zip',\n",
              " 'rri-amplitudes.ipynb',\n",
              " 'kaggle.json',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "os.listdir(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD3vvjjqJhpk",
        "outputId": "acae2532-cbce-43a1-dfe4-44cffd296ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  apnea-ecg-database.zip\n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/ANNOTATORS  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/RECORDS  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/SHA256SUMS.txt  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a01.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a01.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a01.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a01.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a01.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a01er.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a01er.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a01er.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a01er.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a01r.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a01r.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a01r.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a02.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a02.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a02.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a02.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a02.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a02er.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a02er.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a02er.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a02er.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a02r.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a02r.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a02r.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a03.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a03.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a03.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a03.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a03.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a03er.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a03er.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a03er.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a03er.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a03r.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a03r.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a03r.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a04.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a04.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a04.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a04.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a04.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a04er.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a04er.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a04er.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a04er.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a04r.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a04r.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a04r.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a05.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a05.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a05.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a05.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a05.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a06.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a06.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a06.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a06.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a06.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a07.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a07.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a07.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a07.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a07.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a08.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a08.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a08.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a08.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a08.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a09.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a09.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a09.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a09.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a09.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a10.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a10.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a10.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a10.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a10.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a11.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a11.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a11.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a11.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a11.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a12.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a12.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a12.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a12.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a12.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a13.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a13.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a13.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a13.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a13.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a14.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a14.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a14.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a14.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a14.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a15.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a15.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a15.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a15.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a15.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a16.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a16.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a16.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a16.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a16.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a17.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a17.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a17.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a17.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a17.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a18.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a18.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a18.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a18.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a18.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a19.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a19.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a19.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a19.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a19.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a20.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a20.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a20.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a20.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/a20.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/additional-information.txt  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/annotations.shtml  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b01.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b01.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b01.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b01.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b01.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b01er.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b01er.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b01er.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b01er.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b01r.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b01r.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b01r.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b02.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b02.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b02.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b02.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b02.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b03.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b03.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b03.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b03.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b03.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b04.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b04.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b04.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b04.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b04.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b05.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b05.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b05.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b05.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/b05.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c01.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c01.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c01.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c01.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c01.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c01er.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c01er.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c01er.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c01er.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c01r.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c01r.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c01r.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c02.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c02.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c02.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c02.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c02.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c02er.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c02er.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c02er.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c02er.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c02r.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c02r.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c02r.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c03.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c03.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c03.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c03.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c03.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c03er.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c03er.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c03er.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c03er.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c03r.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c03r.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c03r.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c04.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c04.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c04.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c04.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c04.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c05.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c05.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c05.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c05.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c05.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c06.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c06.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c06.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c06.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c06.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c07.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c07.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c07.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c07.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c07.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c08.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c08.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c08.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c08.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c08.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c09.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c09.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c09.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c09.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c09.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c10.apn  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c10.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c10.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c10.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/c10.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/challenge/distill.c  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/challenge/index.shtml  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/challenge/summary-training-1  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/challenge/summary-training-2  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/challenge/template-test-1  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/challenge/template-test-2  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/challenge/template-training-1  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/challenge/template-training-2  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/list  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x01.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x01.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x01.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x01.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x02.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x02.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x02.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x02.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x03.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x03.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x03.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x03.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x04.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x04.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x04.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x04.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x05.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x05.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x05.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x05.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x06.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x06.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x06.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x06.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x07.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x07.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x07.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x07.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x08.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x08.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x08.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x08.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x09.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x09.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x09.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x09.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x10.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x10.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x10.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x10.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x11.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x11.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x11.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x11.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x12.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x12.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x12.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x12.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x13.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x13.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x13.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x13.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x14.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x14.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x14.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x14.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x15.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x15.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x15.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x15.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x16.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x16.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x16.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x16.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x17.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x17.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x17.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x17.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x18.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x18.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x18.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x18.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x19.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x19.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x19.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x19.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x20.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x20.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x20.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x20.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x21.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x21.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x21.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x21.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x22.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x22.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x22.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x22.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x23.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x23.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x23.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x23.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x24.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x24.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x24.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x24.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x25.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x25.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x25.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x25.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x26.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x26.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x26.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x26.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x27.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x27.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x27.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x27.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x28.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x28.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x28.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x28.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x29.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x29.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x29.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x29.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x30.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x30.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x30.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x30.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x31.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x31.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x31.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x31.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x32.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x32.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x32.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x32.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x33.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x33.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x33.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x33.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x34.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x34.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x34.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x34.xws  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x35.dat  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x35.hea  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x35.qrs  \n",
            "  inflating: apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0/x35.xws  \n",
            "  inflating: event-2-answers         \n"
          ]
        }
      ],
      "source": [
        "!unzip apnea-ecg-database.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRdDwT1DL8U2",
        "outputId": "c638a3e7-2a92-46e3-e41e-614244754136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biosppy in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: bidict in /usr/local/lib/python3.10/dist-packages (from biosppy) (0.22.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from biosppy) (3.8.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from biosppy) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.10.1)\n",
            "Requirement already satisfied: shortuuid in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.0.11)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.3.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from biosppy) (4.7.0.72)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->biosppy) (3.2.0)\n",
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.10/dist-packages (4.1.2)\n",
            "Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (0.12.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from wfdb) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->wfdb) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (3.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install biosppy\n",
        "!pip install wfdb\n",
        "\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import posixpath\n",
        "import csv\n",
        "import wfdb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9qxMuYgHHVm",
        "outputId": "e16821b6-26bc-4adf-8901-c7d553a91b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n",
            "c10: 100%|██████████| 431/431 [43:34<00:00,  6.07s/it]\n",
            "c09:  91%|█████████ | 425/468 [44:01<04:23,  6.13s/it]\n",
            "b04: 100%|██████████| 429/429 [44:29<00:00,  6.22s/it]\n",
            "b05: 100%|██████████| 433/433 [46:28<00:00,  6.44s/it]\n",
            "c03: 100%|██████████| 454/454 [46:27<00:00,  6.14s/it]\n",
            "c01:  94%|█████████▍| 455/484 [47:17<02:50,  5.90s/it]\n",
            "b03: 100%|██████████| 441/441 [47:37<00:00,  6.48s/it]\n",
            "c09: 100%|██████████| 468/468 [47:45<00:00,  6.12s/it]\n",
            "c05:  93%|█████████▎| 435/466 [48:08<02:46,  5.37s/it]\n",
            "c04: 100%|██████████| 482/482 [48:45<00:00,  6.07s/it]\n",
            "a04: 100%|██████████| 492/492 [49:31<00:00,  6.04s/it]\n",
            "c01: 100%|██████████| 484/484 [49:29<00:00,  6.14s/it]\n",
            "a18: 100%|██████████| 489/489 [49:39<00:00,  6.09s/it]\n",
            "a01: 100%|██████████| 489/489 [49:49<00:00,  6.11s/it]\n",
            "a11: 100%|██████████| 466/466 [49:56<00:00,  6.43s/it]\n",
            "a16: 100%|██████████| 482/482 [50:02<00:00,  6.23s/it]\n",
            "c05: 100%|██████████| 466/466 [50:08<00:00,  6.46s/it]\n",
            "c02: 100%|██████████| 502/502 [50:12<00:00,  6.00s/it]\n",
            "c06: 100%|██████████| 468/468 [50:13<00:00,  6.44s/it]\n",
            "a09: 100%|██████████| 495/495 [50:32<00:00,  6.13s/it]\n",
            "a14: 100%|██████████| 509/509 [50:39<00:00,  5.97s/it]\n",
            "a13: 100%|██████████| 495/495 [50:51<00:00,  6.16s/it]\n",
            "a08: 100%|██████████| 501/501 [51:00<00:00,  6.11s/it]\n",
            "a10: 100%|██████████| 517/517 [51:03<00:00,  5.93s/it]\n",
            "a07: 100%|██████████| 511/511 [51:06<00:00,  6.00s/it]\n",
            "c08: 100%|██████████| 513/513 [51:03<00:00,  5.97s/it]\n",
            "a03: 100%|██████████| 519/519 [51:11<00:00,  5.92s/it]\n",
            "b02: 100%|██████████| 517/517 [51:07<00:00,  5.93s/it]\n",
            "b01: 100%|██████████| 487/487 [51:27<00:00,  6.34s/it]\n",
            "a20: 100%|██████████| 510/510 [51:36<00:00,  6.07s/it]\n",
            "a15: 100%|██████████| 510/510 [51:53<00:00,  6.11s/it]\n",
            "a06: 100%|██████████| 510/510 [51:59<00:00,  6.12s/it]\n",
            "a12: 100%|██████████| 577/577 [52:13<00:00,  5.43s/it]\n",
            "a02: 100%|██████████| 528/528 [52:17<00:00,  5.94s/it]\n",
            "a17: 100%|██████████| 485/485 [52:22<00:00,  6.48s/it]\n",
            "\n",
            "Testing...\n",
            "x07:  78%|███████▊  | 398/509 [39:28<11:49,  6.39s/it]\n",
            "x24: 100%|██████████| 429/429 [41:44<00:00,  5.84s/it]\n",
            "x06: 100%|██████████| 450/450 [44:44<00:00,  5.97s/it]\n",
            "x18: 100%|██████████| 459/459 [45:41<00:00,  5.97s/it]\n",
            "x22: 100%|██████████| 482/482 [46:54<00:00,  5.84s/it]\n",
            "x35: 100%|██████████| 483/483 [46:57<00:00,  5.83s/it]\n",
            "x11: 100%|██████████| 457/457 [47:27<00:00,  6.23s/it]\n",
            "x29: 100%|██████████| 470/470 [47:31<00:00,  6.07s/it]\n",
            "x04: 100%|██████████| 482/482 [49:08<00:00,  6.12s/it]\n",
            "x33: 100%|██████████| 473/473 [49:27<00:00,  6.27s/it]\n",
            "x07: 100%|██████████| 509/509 [49:33<00:00,  5.84s/it]\n",
            "x34: 100%|██████████| 475/475 [49:41<00:00,  6.28s/it]\n",
            "x19: 100%|██████████| 487/487 [49:43<00:00,  6.13s/it]\n",
            "x16: 100%|██████████| 515/515 [50:29<00:00,  5.88s/it]\n",
            "x21: 100%|██████████| 510/510 [50:29<00:00,  5.94s/it]\n",
            "x05: 100%|██████████| 505/505 [50:39<00:00,  6.02s/it]\n",
            "x03: 100%|██████████| 465/465 [50:40<00:00,  6.54s/it]\n",
            "x30: 100%|██████████| 511/511 [51:04<00:00,  6.00s/it]\n",
            "x27:  96%|█████████▋| 480/498 [51:28<00:56,  3.15s/it]\n",
            "x25: 100%|██████████| 510/510 [51:38<00:00,  6.08s/it]\n",
            "x26: 100%|██████████| 520/520 [51:40<00:00,  5.96s/it]\n",
            "x08: 100%|██████████| 517/517 [51:56<00:00,  6.03s/it]\n",
            "x10: 100%|██████████| 510/510 [52:10<00:00,  6.14s/it]\n",
            "x27: 100%|██████████| 498/498 [52:14<00:00,  6.29s/it]\n",
            "x09: 100%|██████████| 508/508 [52:16<00:00,  6.17s/it]\n",
            "x02: 100%|██████████| 469/469 [52:17<00:00,  6.69s/it]\n",
            "x28: 100%|██████████| 495/495 [52:19<00:00,  6.34s/it]\n",
            "x15: 100%|██████████| 498/498 [52:20<00:00,  6.31s/it]\n",
            "x20: 100%|██████████| 513/513 [52:24<00:00,  6.13s/it]\n",
            "x32: 100%|██████████| 538/538 [52:26<00:00,  5.85s/it]\n",
            "x23: 100%|██████████| 527/527 [52:29<00:00,  5.98s/it]\n",
            "x13: 100%|██████████| 506/506 [52:30<00:00,  6.23s/it]\n",
            "x14: 100%|██████████| 490/490 [52:35<00:00,  6.44s/it]\n",
            "x31: 100%|██████████| 557/557 [52:35<00:00,  5.67s/it]\n",
            "x12: 100%|██████████| 527/527 [52:58<00:00,  6.03s/it]\n",
            "\n",
            "ok!\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import sys\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "\n",
        "import biosppy.signals.tools as st\n",
        "import numpy as np\n",
        "import os\n",
        "import wfdb\n",
        "from biosppy.signals.ecg import correct_rpeaks, hamilton_segmenter\n",
        "from scipy.signal import medfilt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# PhysioNet Apnea-ECG dataset\n",
        "# url: https://physionet.org/physiobank/database/apnea-ecg/\n",
        "#base_dir = \"../input/apnea-ecg-database/apnea-ecg-database-1.0.0\"\n",
        "base_dir = \"apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0\"\n",
        "#base_dir = \"physionet.org/files/apnea-ecg/1.0.0\"\n",
        "\n",
        "\n",
        "\n",
        "fs = 100\n",
        "sample = fs * 60  # 1 min's sample points\n",
        "\n",
        "before = 2  # forward interval (min)\n",
        "after = 2  # backward interval (min)\n",
        "hr_min = 20\n",
        "hr_max = 300\n",
        "\n",
        "num_worker = 35\n",
        "\n",
        "\n",
        "def worker(name, labels):\n",
        "    X = []\n",
        "    y = []\n",
        "    groups = []\n",
        "    signals = wfdb.rdrecord(os.path.join(base_dir, name), channels=[0]).p_signal[:, 0]\n",
        "    for j in tqdm(range(len(labels)), desc=name, file=sys.stdout):\n",
        "        if j < before or \\\n",
        "                (j + 1 + after) > len(signals) / float(sample):\n",
        "            continue\n",
        "        signal = signals[int((j - before) * sample):int((j + 1 + after) * sample)]\n",
        "        signal, _, _ = st.filter_signal(signal, ftype='FIR', band='bandpass', order=int(0.3 * fs),\n",
        "                                        frequency=[3, 45], sampling_rate=fs)\n",
        "        # Find R peaks\n",
        "        rpeaks, = hamilton_segmenter(signal, sampling_rate=fs)\n",
        "        rpeaks, = correct_rpeaks(signal, rpeaks=rpeaks, sampling_rate=fs, tol=0.1)\n",
        "        if len(rpeaks) / (1 + after + before) < 40 or \\\n",
        "                len(rpeaks) / (1 + after + before) > 200:  # Remove abnormal R peaks signal\n",
        "            continue\n",
        "        # Extract RRI, Ampl signal\n",
        "        rri_tm, rri_signal = rpeaks[1:] / float(fs), np.diff(rpeaks) / float(fs)\n",
        "        rri_signal = medfilt(rri_signal, kernel_size=3)\n",
        "        ampl_tm, ampl_siganl = rpeaks / float(fs), signal[rpeaks]\n",
        "        hr = 60 / rri_signal\n",
        "        # Remove physiologically impossible HR signal\n",
        "        if np.all(np.logical_and(hr >= hr_min, hr <= hr_max)):\n",
        "            # Save extracted signal\n",
        "            X.append([(rri_tm, rri_signal), (ampl_tm, ampl_siganl)])\n",
        "            y.append(0. if labels[j] == 'N' else 1.)\n",
        "            groups.append(name)\n",
        "    return X, y, groups\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    apnea_ecg = {}\n",
        "\n",
        "    names = [\n",
        "        \"a01\", \"a02\", \"a03\", \"a04\", \"a05\", \"a06\", \"a07\", \"a08\", \"a09\", \"a10\",\n",
        "        \"a11\", \"a12\", \"a13\", \"a14\", \"a15\", \"a16\", \"a17\", \"a18\", \"a19\", \"a20\",\n",
        "        \"b01\", \"b02\", \"b03\", \"b04\", \"b05\",\n",
        "        \"c01\", \"c02\", \"c03\", \"c04\", \"c05\", \"c06\", \"c07\", \"c08\", \"c09\", \"c10\"\n",
        "    ]\n",
        "\n",
        "    o_train = []\n",
        "    y_train = []\n",
        "    groups_train = []\n",
        "    print('Training...')\n",
        "    with ProcessPoolExecutor(max_workers=num_worker) as executor:\n",
        "        task_list = []\n",
        "        for i in range(len(names)):\n",
        "            labels = wfdb.rdann(os.path.join(base_dir, names[i]), extension=\"apn\").symbol\n",
        "            task_list.append(executor.submit(worker, names[i], labels))\n",
        "\n",
        "        for task in as_completed(task_list):\n",
        "            X, y, groups = task.result()\n",
        "            o_train.extend(X)\n",
        "            y_train.extend(y)\n",
        "            groups_train.extend(groups)\n",
        "\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "    answers = {}\n",
        "    with open(os.path.join(\"event-2-answers\"), \"r\") as f:\n",
        "    #    with open(os.path.join(base_dir, \"event-2-answers\"), \"r\") as f:\n",
        "        for answer in f.read().split(\"\\n\\n\"):\n",
        "            answers[answer[:3]] = list(\"\".join(answer.split()[2::2]))\n",
        "\n",
        "    names = [\n",
        "        \"x01\", \"x02\", \"x03\", \"x04\", \"x05\", \"x06\", \"x07\", \"x08\", \"x09\", \"x10\",\n",
        "        \"x11\", \"x12\", \"x13\", \"x14\", \"x15\", \"x16\", \"x17\", \"x18\", \"x19\", \"x20\",\n",
        "        \"x21\", \"x22\", \"x23\", \"x24\", \"x25\", \"x26\", \"x27\", \"x28\", \"x29\", \"x30\",\n",
        "        \"x31\", \"x32\", \"x33\", \"x34\", \"x35\"\n",
        "    ]\n",
        "\n",
        "    o_test = []\n",
        "    y_test = []\n",
        "    groups_test = []\n",
        "    print(\"Testing...\")\n",
        "    with ProcessPoolExecutor(max_workers=num_worker) as executor:\n",
        "\n",
        "        task_list = []\n",
        "        for i in range(len(names)):\n",
        "            labels = answers[names[i]]\n",
        "            task_list.append(executor.submit(worker, names[i], labels))\n",
        "\n",
        "        for task in as_completed(task_list):\n",
        "            X, y, groups = task.result()\n",
        "            o_test.extend(X)\n",
        "            y_test.extend(y)\n",
        "            groups_test.extend(groups)\n",
        "\n",
        "    apnea_ecg = dict(o_train=o_train, y_train=y_train, groups_train=groups_train, o_test=o_test, y_test=y_test,\n",
        "                     groups_test=groups_test)\n",
        "    with open(os.path.join(base_dir, \"apnea-ecg.pkl\"), \"wb\") as f:\n",
        "        pickle.dump(apnea_ecg, f, protocol=2)\n",
        "\n",
        "    print(\"\\nok!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMgz0mdoqbA3",
        "outputId": "f57aa317-acd3-41f6-eece-808c61a167a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.13)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "#\n",
        "#IMPORT LIBRARIES\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "import os\n",
        "from keras.callbacks import LearningRateScheduler,EarlyStopping\n",
        "from keras.layers import Dense,Flatten,MaxPooling2D,Conv2D,BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from scipy.interpolate import splev, splrep\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.layers import Input\n",
        "import pandas as pd\n",
        "\n",
        "#base_dir = \"dataset\"\n",
        "base_dir = \"apnea-ecg-database-1.0.0/apnea-ecg-database-1.0.0\"\n",
        "#base_dir = \"physionet.org/files/apnea-ecg/1.0.0\"\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# DEEP LEARNING MODELS NEED TO VECTORS OR MATRIX WITH SAME SIZE\n",
        "# R-R INTERVALS DONT HAVE SAME SIZE, SO WE NEED TO INTERPOLATE VECTORS TO GET VECTORS WITH SAME SIZE.\n",
        "# BASED ON OUR EXPERIENCE INTERPOLATION IN 3 HZ BETTER AND ACCURATE.\n",
        "ir = 3 # INTERPOLATION RATE(3HZ)\n",
        "time_range= 60 # 60-s INTERVALS OF ECG SIGNALS\n",
        "weight=1e-3 #  WEIGHT L2 FOR REGULARIZATION(AVODING OVERFITTING PARAMETER)\n",
        "#-----------------------------\n",
        "# NORMALIZATION:\n",
        "# DEEP LEARNING AND EVEN NEURAL NETWORKS INPUT SHOULD BE NORMALIZED:\n",
        "# MIN-MAX METHOD APPLIED FOR SCALING:(Array-min(Array))/(max(Array)-min(Array))\n",
        "scaler = lambda arr: (arr - np.min(arr)) / (np.max(arr) - np.min(arr))\n",
        "#-----------------------------\n",
        "# FIRSTLY WE PRE-PROCESSED OUR DATA IN \"apnea-ecg.pkl\" FILE\n",
        "# IN PRE-PROCESSING SECTION WE EXTRACT R-R INTERVALS AND R-PEAK AMPLITUDES\n",
        "# IN THIS PART WE LOAD THIS DATA AND INTERPOLATE AND CONCATE FOR FEEDING TO NETWORKS\n",
        "def load_data():\n",
        "    tm = np.arange(0, (before + 1 + after) * 60, step=1 / float(ir))\n",
        "\n",
        "    with open(os.path.join(base_dir, \"apnea-ecg.pkl\"), 'rb') as f: # read preprocessing result\n",
        "        apnea_ecg = pickle.load(f)\n",
        "#-----------------\n",
        "    x_train = []\n",
        "    o_train, y_train = apnea_ecg[\"o_train\"], apnea_ecg[\"y_train\"]\n",
        "\n",
        "    for i in range(len(o_train)):\n",
        "        (rri_tm, rri_signal), (amp_tm, amp_signal) = o_train[i]\n",
        "      # Curve interpolation\n",
        "        rri_interp_signal = splev(tm, splrep(rri_tm, scaler(rri_signal), k=3), ext=1)\n",
        "        amp_interp_signal = splev(tm, splrep(amp_tm, scaler(amp_signal), k=3), ext=1)\n",
        "        x_train.append([rri_interp_signal, amp_interp_signal])\n",
        "    x_train = np.array(x_train, dtype=\"float32\")\n",
        "\n",
        "    x_train = np.expand_dims(x_train,1)\n",
        "    x_train=np.array(x_train, dtype=\"float32\").transpose((0,3,1,2)) # convert to numpy format\n",
        "\n",
        "    #return x_train_final, y_train\n",
        "    return x_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rfTpl_4AouT",
        "outputId": "e3341a56-24bd-4f62-e077-39a603e0ecde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Hyperactive in /usr/local/lib/python3.10/dist-packages (4.4.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from Hyperactive) (1.22.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from Hyperactive) (4.65.0)\n",
            "Requirement already satisfied: pandas<2.0.0 in /usr/local/lib/python3.10/dist-packages (from Hyperactive) (1.5.3)\n",
            "Requirement already satisfied: gradient-free-optimizers<2.0.0,>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from Hyperactive) (1.3.0)\n",
            "Requirement already satisfied: scipy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradient-free-optimizers<2.0.0,>=1.2.4->Hyperactive) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn!=0.23.*,>=0.21 in /usr/local/lib/python3.10/dist-packages (from gradient-free-optimizers<2.0.0,>=1.2.4->Hyperactive) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0->Hyperactive) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0->Hyperactive) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0->Hyperactive) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.23.*,>=0.21->gradient-free-optimizers<2.0.0,>=1.2.4->Hyperactive) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.23.*,>=0.21->gradient-free-optimizers<2.0.0,>=1.2.4->Hyperactive) (3.2.0)\n",
            "Requirement already satisfied: mealpy in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from mealpy) (1.22.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from mealpy) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from mealpy) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from mealpy) (1.5.3)\n",
            "Requirement already satisfied: opfunu>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from mealpy) (1.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->mealpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->mealpy) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->mealpy) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Hyperactive\n",
        "!pip install mealpy\n",
        "\n",
        "from hyperactive import Hyperactive\n",
        "from hyperactive.optimizers import HillClimbingOptimizer\n",
        "from tensorflow.keras import optimizers\n",
        "#from Hyperactive.hyperactive import RandomSearchOptimizer, MHoneyBadgerAlgorithm, HoneyBadgerAlgorithm\n",
        "from keras.optimizers import adam\n",
        "import threading\n",
        "import concurrent.futures\n",
        "from threading import Thread\n",
        "import time\n",
        "from tabnanny import verbose\n",
        "from mealpy.swarm_based.HBA import OriginalHBA\n",
        "from tensorflow.python.keras import optimizers\n",
        "from keras.optimizers import adam\n",
        "#from HBA import HBA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWwa-AjL1iY9",
        "outputId": "8fb94dd3-185c-434f-bb67-3dd2d5252ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:Solving 8-objective optimization problem with weights: [0.4 1.  1.  1.  1.  1.  1.  1. ].\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 1, Current best: 933.0214147544652, Global best: 933.0214147544652, Runtime: 0.01115 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 2, Current best: 853.0214147544652, Global best: 853.0214147544652, Runtime: 0.01176 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 3, Current best: 848.0163198269552, Global best: 848.0163198269552, Runtime: 0.02865 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 4, Current best: 844.0004, Global best: 844.0004, Runtime: 0.01282 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 5, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01317 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 6, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01358 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 7, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01221 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 8, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01221 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 9, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01021 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 10, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01187 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 11, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01475 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 12, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01428 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 13, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01045 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 14, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01046 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 15, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01008 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 16, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01050 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 17, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01135 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 18, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01247 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 19, Current best: 843.0004, Global best: 843.0004, Runtime: 0.00983 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 20, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01235 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 21, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01029 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 22, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01148 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 23, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01099 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 24, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01075 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 25, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01072 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 26, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01203 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 27, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01069 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 28, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01080 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 29, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01248 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 30, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01024 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 31, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01230 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 32, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01045 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 33, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01110 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 34, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01053 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 35, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01189 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 36, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01101 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 37, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01113 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 38, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01046 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 39, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01117 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 40, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01102 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 41, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01011 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 42, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01036 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 43, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01059 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 44, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01143 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 45, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01056 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 46, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01036 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 47, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01144 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 48, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01039 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 49, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01077 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 50, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01094 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 51, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01112 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 52, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01215 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 53, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01155 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 54, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01146 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 55, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01102 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 56, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01536 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 57, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01319 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 58, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01430 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 59, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01201 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 60, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01220 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 61, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01077 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 62, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01220 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 63, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01271 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 64, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01170 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 65, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01209 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 66, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01394 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 67, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01268 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 68, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01306 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 69, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01175 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 70, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01118 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 71, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01145 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 72, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01143 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 73, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01151 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 74, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01355 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 75, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01169 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 76, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01116 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 77, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01105 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 78, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01214 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 79, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01081 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 80, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01121 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 81, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01204 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 82, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01086 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 83, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01124 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 84, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01171 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 85, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01126 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 86, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01016 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 87, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01782 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 88, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01934 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 89, Current best: 843.0004, Global best: 843.0004, Runtime: 0.02023 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 90, Current best: 843.0004, Global best: 843.0004, Runtime: 0.02085 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 91, Current best: 843.0004, Global best: 843.0004, Runtime: 0.02228 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 92, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01075 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 93, Current best: 843.0004, Global best: 843.0004, Runtime: 0.03351 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 94, Current best: 843.0004, Global best: 843.0004, Runtime: 0.03114 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 95, Current best: 843.0004, Global best: 843.0004, Runtime: 0.05600 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 96, Current best: 843.0004, Global best: 843.0004, Runtime: 0.03167 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 97, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01129 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 98, Current best: 843.0004, Global best: 843.0004, Runtime: 0.02936 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 99, Current best: 843.0004, Global best: 843.0004, Runtime: 0.03161 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 100, Current best: 843.0004, Global best: 843.0004, Runtime: 0.02091 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution: [1.00e-03 4.80e+01 1.28e+02 1.92e+02 1.92e+02 1.28e+02 1.05e+02 5.00e+01], Fitness: (0.001, 48, 128, 192, 192, 128, 105, 50)\n"
          ]
        }
      ],
      "source": [
        "# BHA\n",
        "###########################\n",
        "def fitness_function(position):\n",
        "    learning_rate,n1,n2,n3,n4,n5,n6,epochs = position[0],position[1],position[2],position[3],position[4],position[5],position[6],position[7]\n",
        "    n1,n2,n3,n4,n5,n6,epochs=int(n1),int(n2),int(n3),int(n4),int(n5),int(n6),int(epochs)\n",
        "    #return learning_rate,n1,n2,n3,n4,n5,n6,epochs\n",
        "\n",
        "    print(learning_rate,n1,n2,n3,n4,n5,n6,epochs)\n",
        "\n",
        "#def create_model(weight=1e-3):\n",
        "    model= Sequential()\n",
        "    model.add(Conv2D(n1, kernel_size=(11,1), strides=(1,1), padding=\"valid\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight),input_shape=(900,1,2)))    #,input_shape=(180,1,2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3,1)))\n",
        "    model.add(Conv2D(n2, kernel_size=(5,1), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3,1)))\n",
        "    model.add(Conv2D(n3, kernel_size=(3,1), strides=(1,1), padding=\"valid\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(n4, kernel_size=(3,1), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(n5, kernel_size=(3,1), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3,1),strides=(2,1)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(n6, activation=\"relu\"))\n",
        "    model.add(Dense(2, activation=\"softmax\"))\n",
        "\n",
        "    optimizer =keras.optimizers.Adam(lr=learning_rate)\n",
        "    print(\"Learning rate: \", learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "    #model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "    history=model.fit(X1, Y1, batch_size=128, epochs=int(epochs), validation_data=(x_val, y_val),\n",
        "                       callbacks=[callback1,lr_scheduler])\n",
        "\n",
        "\n",
        "    #history = model.fit(x_train,y_train, epochs=int(epochs),batch_size=32, validation_data=(x_test, y_test))\n",
        "    return history.history['val_accuracy'][-1]\n",
        "    #loss, accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "    #return model\n",
        "#------------------------------------------------------------------------------\n",
        "# Define learning rate schedule for preventing overfitting in deep learning methods:\n",
        "def lr_schedule(epochs, learning_rate):\n",
        "   if epochs > 70 and \\\n",
        "           (epochs - 1) % 10 == 0:\n",
        "        learning_rate *= 0.1\n",
        "   print(\"Learning rate: \", learning_rate)\n",
        "   return learning_rate\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "        # we used k-fold cross-validation for more reliable experiments:\n",
        "   kfold = StratifiedKFold(n_splits=5, shuffle=True,random_state=7)\n",
        "   cvscores = []\n",
        "   ACC=[]\n",
        "   SN=[]\n",
        "   SP=[]\n",
        "   F2=[]\n",
        "\n",
        "   print(\"train num:\", len(y_train))\n",
        "   print(\"test num:\", len(y_test))\n",
        "\n",
        "    # separate train& test and then compile model\n",
        "   for train, test in kfold.split(x_train, y_train.argmax(1)):\n",
        "     model = create_model()\n",
        "     model.summary()\n",
        "\n",
        "     # Compile and evaluate model:\n",
        "if __name__ == \"__main__\":\n",
        "    # loading Data:\n",
        "    x_train, y_train = load_data()\n",
        "    # we have labels(Y) in a binary way 0 for normal and 1 for apnea patients\n",
        "    # we want to classify data into 2-class so we changed y in a categorical way:\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "    # we used k-fold cross-validation for more reliable experiments:\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True,random_state=7)\n",
        "\n",
        "\n",
        "    # separate train& test and then compile model\n",
        "    ##for train, test in kfold.split(x_train, y_train.argmax(1)):\n",
        "     #model = create_model()\n",
        "     #model.summary()\n",
        "\n",
        "    # define callback for early stopping:\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "    callback1 = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    #10% of Data used for validation:\n",
        "    X1,x_val,Y1,y_val=train_test_split(x_train,y_train,test_size=0.10)\n",
        "\n",
        "##################################################################\n",
        "#pso = Pso(swarmsize=4,maxiter=14)\n",
        "# n,sf,sp,l\n",
        "##bp,value = pso.run(func,[1,2,2,2],[16,8,4,4])\n",
        "#v = func(bp);\n",
        "##################################################################\n",
        "problem_dict1 = {\n",
        "    \"fit_func\": fitness_function,\n",
        "    'lb':[0.001,48,128,192,192,128,105,50], # Lower bound of our parameters\n",
        "    'ub':[0.1,192,512,768,768,512,418,200], # upper bound of our parameters\n",
        "    \"minmax\": \"min\",\n",
        "    \"obj_weights\": [0.4, 1, 1,1,1,1,1,1]               # Define it or default value will be [1, 1, 1]   [0.4, 0.1, 0.5,1,1,1,1,1]\n",
        "                }\n",
        "\n",
        "epoch = 100\n",
        "pop_size = 50\n",
        "\n",
        "#def thread_function(k):\n",
        "\n",
        "  #run=k+1\n",
        "  #print(\"Run Number\",run)\n",
        "  #Optimizer = MHoneyBadgerAlgorithm(search_config, n_iter=100, n_part=10, metric='accuracy', cv=10, h_beta=6.0, h_c=2.0,run=run)\n",
        "model = OriginalHBA(epoch, pop_size)\n",
        "  #t1 = time.time()\n",
        "\n",
        "  #Optimizer.fit(x_train, y_train)\n",
        " # t2 = time.time()\n",
        "\n",
        "  #print(\"time: {}\".format(t2-t1))\n",
        "\n",
        "\n",
        "\n",
        "#best_position, best_fitness = model.solve(problem_dict1)\n",
        "best_position, best_fitness= model.solve(problem_dict1)\n",
        "v = fitness_function(best_position);\n",
        "#print(f\"Solution: {best_position}, Fitness: {best_fitness}\")\n",
        "print(f\"Solution: {best_position}, Fitness: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb94dd3-185c-434f-bb67-3dd2d5252ef1",
        "id": "HdZk0TGsoq2v"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:Solving 8-objective optimization problem with weights: [0.4 1.  1.  1.  1.  1.  1.  1. ].\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 1, Current best: 933.0214147544652, Global best: 933.0214147544652, Runtime: 0.01115 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 2, Current best: 853.0214147544652, Global best: 853.0214147544652, Runtime: 0.01176 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 3, Current best: 848.0163198269552, Global best: 848.0163198269552, Runtime: 0.02865 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 4, Current best: 844.0004, Global best: 844.0004, Runtime: 0.01282 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 5, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01317 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 6, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01358 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 7, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01221 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 8, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01221 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 9, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01021 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 10, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01187 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 11, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01475 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 12, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01428 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 13, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01045 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 14, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01046 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 15, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01008 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 16, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01050 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 17, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01135 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 18, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01247 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 19, Current best: 843.0004, Global best: 843.0004, Runtime: 0.00983 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 20, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01235 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 21, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01029 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 22, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01148 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 23, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01099 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 24, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01075 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 25, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01072 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 26, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01203 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 27, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01069 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 28, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01080 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 29, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01248 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 30, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01024 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 31, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01230 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 32, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01045 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 33, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01110 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 34, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01053 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 35, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01189 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 36, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01101 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 37, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01113 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 38, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01046 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 39, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01117 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 40, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01102 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 41, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01011 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 42, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01036 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 43, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01059 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 44, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01143 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 45, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01056 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 46, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01036 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 47, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01144 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 48, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01039 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 49, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01077 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 50, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01094 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 51, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01112 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 52, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01215 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 53, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01155 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 54, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01146 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 55, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01102 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 56, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01536 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 57, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01319 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 58, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01430 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 59, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01201 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 60, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01220 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 61, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01077 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 62, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01220 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 63, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01271 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 64, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01170 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 65, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01209 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 66, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01394 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 67, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01268 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 68, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01306 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 69, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01175 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 70, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01118 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 71, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01145 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 72, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01143 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 73, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01151 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 74, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01355 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 75, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01169 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 76, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01116 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 77, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01105 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 78, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01214 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 79, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01081 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 80, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01121 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 81, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01204 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 82, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01086 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 83, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01124 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 84, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01171 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 85, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01126 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 86, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01016 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 87, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01782 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 88, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01934 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 89, Current best: 843.0004, Global best: 843.0004, Runtime: 0.02023 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 90, Current best: 843.0004, Global best: 843.0004, Runtime: 0.02085 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 91, Current best: 843.0004, Global best: 843.0004, Runtime: 0.02228 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 92, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01075 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 93, Current best: 843.0004, Global best: 843.0004, Runtime: 0.03351 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 94, Current best: 843.0004, Global best: 843.0004, Runtime: 0.03114 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 95, Current best: 843.0004, Global best: 843.0004, Runtime: 0.05600 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 96, Current best: 843.0004, Global best: 843.0004, Runtime: 0.03167 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 97, Current best: 843.0004, Global best: 843.0004, Runtime: 0.01129 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 98, Current best: 843.0004, Global best: 843.0004, Runtime: 0.02936 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 99, Current best: 843.0004, Global best: 843.0004, Runtime: 0.03161 seconds\n",
            "INFO:mealpy.swarm_based.HBA.OriginalHBA:>Problem: P, Epoch: 100, Current best: 843.0004, Global best: 843.0004, Runtime: 0.02091 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution: [1.00e-03 4.80e+01 1.28e+02 1.92e+02 1.92e+02 1.28e+02 1.05e+02 5.00e+01], Fitness: (0.001, 48, 128, 192, 192, 128, 105, 50)\n"
          ]
        }
      ],
      "source": [
        "# BHA\n",
        "###########################\n",
        "def fitness_function(position):\n",
        "    learning_rate,n1,n2,n3,n4,n5,n6,epochs = position[0],position[1],position[2],position[3],position[4],position[5],position[6],position[7]\n",
        "    n1,n2,n3,n4,n5,n6,epochs=int(n1),int(n2),int(n3),int(n4),int(n5),int(n6),int(epochs)\n",
        "    ##return learning_rate,n1,n2,n3,n4,n5,n6,epochs\n",
        "\n",
        "    print(learning_rate,n1,n2,n3,n4,n5,n6,epochs)\n",
        "\n",
        "#def create_model(weight=1e-3):\n",
        "    model= Sequential()\n",
        "    model.add(Conv2D(n1, kernel_size=(11,1), strides=(1,1), padding=\"valid\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight),input_shape=(900,1,2)))    #,input_shape=(180,1,2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3,1)))\n",
        "    model.add(Conv2D(n2, kernel_size=(5,1), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3,1)))\n",
        "    model.add(Conv2D(n3, kernel_size=(3,1), strides=(1,1), padding=\"valid\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(n4, kernel_size=(3,1), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(n5, kernel_size=(3,1), strides=1, padding=\"valid\", activation=\"relu\", kernel_initializer=\"he_normal\",\n",
        "                kernel_regularizer=l2(weight), bias_regularizer=l2(weight)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3,1),strides=(2,1)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(n6, activation=\"relu\"))\n",
        "    model.add(Dense(2, activation=\"softmax\"))\n",
        "    return learning_rate,n1,n2,n3,n4,n5,n6,epochs\n",
        "\n",
        "    optimizer =keras.optimizers.Adam(lr=learning_rate)\n",
        "    print(\"Learning rate: \", learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "    #model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "    history=model.fit(X1, Y1, batch_size=128, epochs=int(epochs), validation_data=(x_val, y_val),\n",
        "                       callbacks=[callback1,lr_scheduler])\n",
        "\n",
        "\n",
        "    #history = model.fit(x_train,y_train, epochs=int(epochs),batch_size=32, validation_data=(x_test, y_test))\n",
        "    return history.history['val_accuracy'][-1]\n",
        "    #loss, accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "    #return model\n",
        "#------------------------------------------------------------------------------\n",
        "# Define learning rate schedule for preventing overfitting in deep learning methods:\n",
        "def lr_schedule(epochs, learning_rate):\n",
        "   if epochs > 70 and \\\n",
        "           (epochs - 1) % 10 == 0:\n",
        "        learning_rate *= 0.1\n",
        "   print(\"Learning rate: \", learning_rate)\n",
        "   return learning_rate\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "        # we used k-fold cross-validation for more reliable experiments:\n",
        "   kfold = StratifiedKFold(n_splits=5, shuffle=True,random_state=7)\n",
        "   cvscores = []\n",
        "   ACC=[]\n",
        "   SN=[]\n",
        "   SP=[]\n",
        "   F2=[]\n",
        "\n",
        "   print(\"train num:\", len(y_train))\n",
        "   print(\"test num:\", len(y_test))\n",
        "\n",
        "    # separate train& test and then compile model\n",
        "   for train, test in kfold.split(x_train, y_train.argmax(1)):\n",
        "     model = create_model()\n",
        "     model.summary()\n",
        "\n",
        "     # Compile and evaluate model:\n",
        "if __name__ == \"__main__\":\n",
        "    # loading Data:\n",
        "    x_train, y_train = load_data()\n",
        "    # we have labels(Y) in a binary way 0 for normal and 1 for apnea patients\n",
        "    # we want to classify data into 2-class so we changed y in a categorical way:\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
        "    # we used k-fold cross-validation for more reliable experiments:\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True,random_state=7)\n",
        "\n",
        "\n",
        "    # separate train& test and then compile model\n",
        "    ##for train, test in kfold.split(x_train, y_train.argmax(1)):\n",
        "     #model = create_model()\n",
        "     #model.summary()\n",
        "\n",
        "    # define callback for early stopping:\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "    callback1 = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    #10% of Data used for validation:\n",
        "    X1,x_val,Y1,y_val=train_test_split(x_train,y_train,test_size=0.10)\n",
        "\n",
        "##################################################################\n",
        "#pso = Pso(swarmsize=4,maxiter=14)\n",
        "# n,sf,sp,l\n",
        "##bp,value = pso.run(func,[1,2,2,2],[16,8,4,4])\n",
        "#v = func(bp);\n",
        "##################################################################\n",
        "problem_dict1 = {\n",
        "    \"fit_func\": fitness_function,\n",
        "    'lb':[0.001,48,128,192,192,128,105,50], # Lower bound of our parameters\n",
        "    'ub':[0.1,192,512,768,768,512,418,200], # upper bound of our parameters\n",
        "    \"minmax\": \"min\",\n",
        "    \"obj_weights\": [0.4, 1, 1,1,1,1,1,1]               # Define it or default value will be [1, 1, 1]   [0.4, 0.1, 0.5,1,1,1,1,1]\n",
        "                }\n",
        "\n",
        "epoch = 100\n",
        "pop_size = 50\n",
        "\n",
        "#def thread_function(k):\n",
        "\n",
        "  #run=k+1\n",
        "  #print(\"Run Number\",run)\n",
        "  #Optimizer = MHoneyBadgerAlgorithm(search_config, n_iter=100, n_part=10, metric='accuracy', cv=10, h_beta=6.0, h_c=2.0,run=run)\n",
        "model = OriginalHBA(epoch, pop_size)\n",
        "  #t1 = time.time()\n",
        "\n",
        "  #Optimizer.fit(x_train, y_train)\n",
        " # t2 = time.time()\n",
        "\n",
        "  #print(\"time: {}\".format(t2-t1))\n",
        "\n",
        "\n",
        "\n",
        "#best_position, best_fitness = model.solve(problem_dict1)\n",
        "best_position, best_fitness= model.solve(problem_dict1)\n",
        "v = fitness_function(best_position);\n",
        "#print(f\"Solution: {best_position}, Fitness: {best_fitness}\")\n",
        "print(f\"Solution: {best_position}, Fitness: {v}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMNSxOnPzERP5Ec0r1p99YS"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}